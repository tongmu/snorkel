{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial will show off some of the more advanced features of Snorkel, so we'll assume you've followed the Intro tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reloading from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tong/anaconda3/envs/py27_2/lib/python2.7/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "from snorkel.learning.XGBoost_NoiseAware import XGBoost_NoiseAware\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "test = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).all()\n",
    "\n",
    "print 'Training set:\\t{0} candidates'.format(len(train))\n",
    "print 'Dev set:\\t{0} candidates'.format(len(dev))\n",
    "print 'Test set:\\t{0} candidates'.format(len(test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load stuff\n",
    "import cPickle as pickle\n",
    "with open('test_labels.dat', 'rb') as infile:\n",
    "    L_gold_test_dense_cp = pickle.load(infile)\n",
    "with open('train_labels.dat', 'rb') as infile:\n",
    "    L_gold_train_dense_cp = pickle.load(infile)\n",
    "with open('dev_labels.dat', 'rb') as infile:\n",
    "    L_gold_dev_dense_cp = pickle.load(infile)\n",
    "with open('train_features.dat', 'rb') as infile:\n",
    "    F_train = pickle.load(infile)\n",
    "with open('dev_features.dat', 'rb') as infile:\n",
    "    F_dev = pickle.load(infile)\n",
    "with open('test_features.dat', 'rb') as infile:\n",
    "    F_test = pickle.load(infile)\n",
    "with open('train_marginals.dat', 'rb') as infile:\n",
    "    train_marginals = pickle.load(infile)\n",
    "with open('rounded_train_marginals.dat', 'rb') as infile:\n",
    "    rounded_train_marginals = pickle.load(infile)\n",
    "#dtrain = xgb.DMatrix( \"train.buffer\")\n",
    "#dtrain2 = xgb.DMatrix(\"train2.buffer\")\n",
    "#dtest = xgb.DMatrix(\"test.buffer\")\n",
    "dtrain = xgb.DMatrix( F_train, label=train_marginals)\n",
    "dtest = xgb.DMatrix( F_test, label=L_gold_test_dense_cp)\n",
    "bst = xgb.Booster({'nthread':4}) #init model\n",
    "bst.load_model(\"250.model\") # load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, find\n",
    "F_train.get_key(session, 5253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54427294882209587"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dtest)\n",
    "preds[preds > 0] = 1\n",
    "preds[preds < 0] = 0\n",
    "TP = sum(np.logical_and(preds,L_gold_test_dense_cp))\n",
    "TN = sum(np.logical_and(np.logical_not(preds),np.logical_not(L_gold_test_dense_cp)))\n",
    "FP = sum(np.logical_and(preds,np.logical_not(L_gold_test_dense_cp)))\n",
    "FN = sum(np.logical_and(np.logical_not(preds),L_gold_test_dense_cp))\n",
    "P = TP/float(TP+FP)\n",
    "R = TP/float(FN+TP)\n",
    "F = 2*(P*R)/(P+R)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst, height=.4, max_num_features=30)\n",
    "#xgb.to_graphviz(bst, num_trees=2)\n",
    "#plt.savefig('sample.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_tree(bst, num_trees=194)\n",
    "#plt.savefig('tree249.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_test[:,143].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "from snorkel.annotations import load_gold_labels\n",
    "load_external_labels(session, ChemicalDisease, split=1, annotator='gold')\n",
    "#load_external_labels(session, ChemicalDisease, split=0, annotator='gold')\n",
    "#load_external_labels(session, ChemicalDisease, split=2, annotator='gold')\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "#L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "L_gold_dev_dense_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "L_gold_test_dense = L_gold_test.todense()\n",
    "L_gold_test_dense = np.squeeze(np.asarray(L_gold_test_dense))\n",
    "L_gold_test_dense_cp = copy.deepcopy(L_gold_test_dense)\n",
    "L_gold_test_dense_cp[L_gold_test_dense_cp == -1]=0\n",
    "L_gold_train_dense = L_gold_train.todense()\n",
    "L_gold_train_dense = np.squeeze(np.asarray(L_gold_train_dense))\n",
    "L_gold_train_dense_cp = copy.deepcopy(L_gold_train_dense)\n",
    "L_gold_train_dense_cp[L_gold_train_dense_cp == -1]=0\n",
    "L_gold_test_dense_cp\n",
    "L_gold_dev_dense = L_gold_dev.todense()\n",
    "L_gold_dev_dense = np.squeeze(np.asarray(L_gold_dev_dense))\n",
    "L_gold_dev_dense_cp = copy.deepcopy(L_gold_dev_dense)\n",
    "L_gold_dev_dense_cp[L_gold_dev_dense_cp == -1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()\n",
    "%time F_dev = featurizer.apply(split=1)\n",
    "F_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply Featurizer\n",
    "F_train = featurizer.apply_existing(split=0)\n",
    "F_dev  = featurizer.apply_existing(split=1)\n",
    "F_test = featurizer.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_test  = featurizer.load_matrix(session, split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0-preds)\n",
    "    return grad, hess\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    #preds = 1.0/(1.0+np.exp(-preds))\n",
    "    errors = np.mean(labels*np.log(1+np.exp(-preds))+(1-labels)*np.log(1+np.exp(preds)))\n",
    "    # return a pair metric_name, result\n",
    "    # since preds are margin(before logistic transformation, cutoff at 0)\n",
    "    return 'error', errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "F_test2 = csr_matrix(np.zeros(F_test.shape))\n",
    "dtest2 = xgb.DMatrix( F_test2, label=L_gold_test_dense_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals_test = np.round(train_marginals)\n",
    "dtrain2 = xgb.DMatrix( F_train, label=train_marginals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_train = F_train.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_dev = F_dev.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train')]\n",
    "num_round = 10\n",
    "\n",
    "#param = {'max_depth': 6, 'eta': 1, 'objective':'binary:logistic'}\n",
    "#bst2 = xgb.train(param, dtrain2, num_round, watchlist)\n",
    "\n",
    "#param = {'max_depth': 5, 'eta': 1, 'eval_metric': 'auc'}\n",
    "#bst2 = xgb.train(param, dtrain2, num_round, watchlist, logregobj)\n",
    "\n",
    "param = {'max_depth': 6, 'eta': 1, 'silent':1}\n",
    "bst2 = xgb.train(param, dtrain, num_round, watchlist, logregobj, evalerror, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds2_prob = bst.predict(dtest)\n",
    "preds2[preds2_prob > 0] = 1\n",
    "preds2[preds2_prob < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst2 = xgb.Booster({'nthread':4}) #init model\n",
    "bst2.load_model(\"XGBoost_73.model\") # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds2_prob = bst2.predict(dtest)\n",
    "preds2 = np.round(preds2_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "TP = sum(np.logical_and(preds2,L_gold_test_dense_cp))\n",
    "TN = sum(np.logical_and(np.logical_not(preds2),np.logical_not(L_gold_test_dense_cp)))\n",
    "FP = sum(np.logical_and(preds2,np.logical_not(L_gold_test_dense_cp)))\n",
    "FN = sum(np.logical_and(np.logical_not(preds2),L_gold_test_dense_cp))\n",
    "P = TP/float(TP+FP)\n",
    "R = TP/float(FN+TP)\n",
    "F = 2*(P*R)/(P+R)\n",
    "print(sum(preds2), TP, TN, FP, FN, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = False\n",
    "not(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save stuff\n",
    "import cPickle as pickle\n",
    "with open('dev_labels.dat', 'wb') as outfile:\n",
    "    pickle.dump(L_gold_dev_dense_cp, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_tree(bst2, num_trees=1)\n",
    "plt.savefig('tree1_bad.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix( F_train, label=train_marginals)\n",
    "dtest = xgb.DMatrix( F_test, label=L_gold_test_dense_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save Tree\n",
    "bst2.save_model('250.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save Data\n",
    "dtrain2.save_binary(\"train2.buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.XGBoost_NoiseAware import XGBoost_NoiseAware\n",
    "disc_model = XGBoost_NoiseAware()\n",
    "\n",
    "eta_param = RangeParameter('eta', .05, .3, step=.05)\n",
    "max_depth_param  = RangeParameter('max_depth', 2, 6, step=1)\n",
    "min_child_weight_param  = RangeParameter('min_child_weight', 1, 6, step=1)\n",
    "gamma_param = RangeParameter('gamma', 0, .5, step = .1)\n",
    "num_rounds_param = RangeParameter('num_rounds', 10, 50, 10)\n",
    "\n",
    "searcher = RandomSearch(session, disc_model, F_train, train_marginals, [eta_param, max_depth_param, min_child_weight_param, gamma_param, num_rounds_param], n=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher.fit(F_dev, L_gold_dev_dense_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.XGBoost_NoiseAware import XGBoost_NoiseAware\n",
    "disc_model = XGBoost_NoiseAware()\n",
    "disc_model.train(F_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#disc_model.train(F_test, L_gold_test_dense_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = disc_model.score(session, F_dev, L_gold_dev_dense_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Training an extraction model\n",
    "\n",
    "In the intro tutorial, we automatically featurized the candidates and trained a linear model over these features. Here, we'll train a more complicated model for relation extraction: an LSTM network. You can read more about LSTMs [here](https://en.wikipedia.org/wiki/Long_short-term_memory) or [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/). An LSTM is a type of recurrent neural network and automatically generates a numerical representation for the candidate based on the sentence text, so no need for featurizing explicitly as in the intro tutorial. LSTMs take longer to train, and Snorkel doesn't currently support hyperparameter searches for them. We'll train a single model here, but feel free to try out other parameter sets. Just make sure to use the development set - and not the test set - for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.learning import reLSTM\n",
    "\n",
    "lstm = reLSTM()\n",
    "lstm.train(\n",
    "    train, train_marginals, lr=0.005, dim=200, n_epochs=30,\n",
    "    dropout_rate=0.5, rebalance=0.25, print_freq=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring on the test set\n",
    "\n",
    "Finally, we'll evaluate our performance on the blind test set of 500 documents. We'll load labels similar to how we did for the development set, and use the `score` function of our extraction model to see how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "load_external_labels(session, ChemicalDisease, split=2, annotator='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, _, _ = lstm.score(session, test, L_gold_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
