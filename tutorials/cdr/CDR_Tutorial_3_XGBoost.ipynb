{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial will show off some of the more advanced features of Snorkel, so we'll assume you've followed the Intro tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's start by reloading from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\t8272 candidates\n",
      "Dev set:\t888 candidates\n",
      "Test set:\t4620 candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "test = session.query(ChemicalDisease).filter(ChemicalDisease.split == 2).all()\n",
    "\n",
    "print 'Training set:\\t{0} candidates'.format(len(train))\n",
    "print 'Dev set:\\t{0} candidates'.format(len(dev))\n",
    "print 'Test set:\\t{0} candidates'.format(len(test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load gold lables for validation and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "AnnotatorLabels created: 0\n",
      "AnnotatorLabels created: 0\n"
     ]
    }
   ],
   "source": [
    "from load_external_annotations import load_external_labels\n",
    "from snorkel.annotations import load_gold_labels\n",
    "load_external_labels(session, ChemicalDisease, split=1, annotator='gold')\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "load_external_labels(session, ChemicalDisease, split=0, annotator='gold')\n",
    "L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "load_external_labels(session, ChemicalDisease, split=2, annotator='gold')\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%%\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%%\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()\n",
    "F_train = featurizer.apply(split=0)\n",
    "F_dev  = featurizer.apply_existing(split=1)\n",
    "F_test = featurizer.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've already computed the features, again we can just use the below step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_test  = featurizer.load_matrix(session, split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part V: Training an extraction model\n",
    "\n",
    "In the intro tutorial, we automatically featurized the candidates and trained a linear model over these features. Here, we'll train a more complicated model for relation extraction: an LSTM network. You can read more about LSTMs [here](https://en.wikipedia.org/wiki/Long_short-term_memory) or [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/). An LSTM is a type of recurrent neural network and automatically generates a numerical representation for the candidate based on the sentence text, so no need for featurizing explicitly as in the intro tutorial. LSTMs take longer to train, and Snorkel doesn't currently support hyperparameter searches for them. We'll train a single model here, but feel free to try out other parameter sets. Just make sure to use the development set - and not the test set - for model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Sparse Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "SLR_model = SparseLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 20. Search space size = 125.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# Searching over learning rate\n",
    "rate_param = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l1_param  = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param  = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "\n",
    "SLR_searcher = RandomSearch(session, SLR_model, F_train, train_marginals, [rate_param, l1_param, l2_param], n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing lr = 1.00e-02, l1_penalty = 1.00e-03, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=0.001 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (4.78s)\tAvg. loss=0.689868\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (70.02s)\tAvg. loss=0.637209\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (130.82s)\tAvg. loss=0.640750\tNNZ=122840\n",
      "[SparseLR] Training done (130.82s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_0\n",
      "============================================================\n",
      "[2] Testing lr = 1.00e-04, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.73s)\tAvg. loss=0.769628\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.21s)\tAvg. loss=0.591674\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (127.43s)\tAvg. loss=0.548004\tNNZ=122840\n",
      "[SparseLR] Training done (127.43s)\n",
      "============================================================\n",
      "[3] Testing lr = 1.00e-03, l1_penalty = 1.00e-05, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-05 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.23s)\tAvg. loss=0.705775\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (69.05s)\tAvg. loss=0.496985\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (134.52s)\tAvg. loss=0.493103\tNNZ=122840\n",
      "[SparseLR] Training done (134.52s)\n",
      "[SparseLR] Model saved. To load, use name\n",
      "\t\tSparseLR_2\n",
      "============================================================\n",
      "[4] Testing lr = 1.00e-03, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.85s)\tAvg. loss=0.710613\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (65.39s)\tAvg. loss=0.500049\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (124.90s)\tAvg. loss=0.495639\tNNZ=122840\n",
      "[SparseLR] Training done (124.90s)\n",
      "============================================================\n",
      "[5] Testing lr = 1.00e-02, l1_penalty = 1.00e-04, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=0.0001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.88s)\tAvg. loss=0.653821\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (65.39s)\tAvg. loss=0.625065\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (125.63s)\tAvg. loss=0.632481\tNNZ=122840\n",
      "[SparseLR] Training done (125.63s)\n",
      "============================================================\n",
      "[6] Testing lr = 1.00e-06, l1_penalty = 1.00e-03, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.88s)\tAvg. loss=0.841446\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.19s)\tAvg. loss=0.835533\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (126.76s)\tAvg. loss=0.830129\tNNZ=122840\n",
      "[SparseLR] Training done (126.76s)\n",
      "============================================================\n",
      "[7] Testing lr = 1.00e-06, l1_penalty = 1.00e-03, l2_penalty = 1.00e-02\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.001 l2=0.01\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.38s)\tAvg. loss=0.916895\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.47s)\tAvg. loss=0.910308\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (127.23s)\tAvg. loss=0.904265\tNNZ=122840\n",
      "[SparseLR] Training done (127.23s)\n",
      "============================================================\n",
      "[8] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-02\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=0.01\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.43s)\tAvg. loss=0.667042\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (67.48s)\tAvg. loss=0.620250\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (128.25s)\tAvg. loss=0.615180\tNNZ=122840\n",
      "[SparseLR] Training done (128.25s)\n",
      "============================================================\n",
      "[9] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.88s)\tAvg. loss=1.707576\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (67.56s)\tAvg. loss=1.012609\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (129.19s)\tAvg. loss=0.762751\tNNZ=122840\n",
      "[SparseLR] Training done (129.19s)\n",
      "============================================================\n",
      "[10] Testing lr = 1.00e-06, l1_penalty = 1.00e-05, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=1e-05 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.93s)\tAvg. loss=0.764888\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.17s)\tAvg. loss=0.758803\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (128.04s)\tAvg. loss=0.753226\tNNZ=122840\n",
      "[SparseLR] Training done (128.04s)\n",
      "============================================================\n",
      "[11] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.05s)\tAvg. loss=1.714658\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.44s)\tAvg. loss=1.015526\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (127.66s)\tAvg. loss=0.765612\tNNZ=122840\n",
      "[SparseLR] Training done (127.66s)\n",
      "============================================================\n",
      "[12] Testing lr = 1.00e-03, l1_penalty = 1.00e-06, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-06 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (2.95s)\tAvg. loss=0.698145\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.51s)\tAvg. loss=0.500623\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (136.56s)\tAvg. loss=0.496317\tNNZ=122840\n",
      "[SparseLR] Training done (136.56s)\n",
      "============================================================\n",
      "[13] Testing lr = 1.00e-04, l1_penalty = 1.00e-04, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.0001 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.75s)\tAvg. loss=0.804486\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (65.62s)\tAvg. loss=0.594061\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (125.50s)\tAvg. loss=0.550307\tNNZ=122840\n",
      "[SparseLR] Training done (125.50s)\n",
      "============================================================\n",
      "[14] Testing lr = 1.00e-03, l1_penalty = 1.00e-05, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.001 l1=1e-05 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.03s)\tAvg. loss=0.706362\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (65.53s)\tAvg. loss=0.498136\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (127.99s)\tAvg. loss=0.494422\tNNZ=122840\n",
      "[SparseLR] Training done (127.99s)\n",
      "============================================================\n",
      "[15] Testing lr = 1.00e-04, l1_penalty = 1.00e-02, l2_penalty = 1.00e-05\n",
      "============================================================\n",
      "[SparseLR] lr=0.0001 l1=0.01 l2=1e-05\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.07s)\tAvg. loss=1.706741\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (66.57s)\tAvg. loss=1.016551\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (136.15s)\tAvg. loss=0.764304\tNNZ=122840\n",
      "[SparseLR] Training done (136.16s)\n",
      "============================================================\n",
      "[16] Testing lr = 1.00e-05, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=1e-05 l1=1e-06 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.14s)\tAvg. loss=0.793591\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (68.16s)\tAvg. loss=0.735703\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (128.81s)\tAvg. loss=0.699018\tNNZ=122840\n",
      "[SparseLR] Training done (128.81s)\n",
      "============================================================\n",
      "[17] Testing lr = 1.00e-06, l1_penalty = 1.00e-02, l2_penalty = 1.00e-03\n",
      "============================================================\n",
      "[SparseLR] lr=1e-06 l1=0.01 l2=0.001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.16s)\tAvg. loss=1.737412\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (67.39s)\tAvg. loss=1.723950\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (128.75s)\tAvg. loss=1.711341\tNNZ=122840\n",
      "[SparseLR] Training done (128.75s)\n",
      "============================================================\n",
      "[18] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.19s)\tAvg. loss=0.653866\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (67.43s)\tAvg. loss=0.647095\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (128.44s)\tAvg. loss=0.646611\tNNZ=122840\n",
      "[SparseLR] Training done (128.44s)\n",
      "============================================================\n",
      "[19] Testing lr = 1.00e-05, l1_penalty = 1.00e-02, l2_penalty = 1.00e-06\n",
      "============================================================\n",
      "[SparseLR] lr=1e-05 l1=0.01 l2=1e-06\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.17s)\tAvg. loss=1.735856\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (65.90s)\tAvg. loss=1.619804\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (127.75s)\tAvg. loss=1.522661\tNNZ=122840\n",
      "[SparseLR] Training done (127.75s)\n",
      "============================================================\n",
      "[20] Testing lr = 1.00e-02, l1_penalty = 1.00e-05, l2_penalty = 1.00e-04\n",
      "============================================================\n",
      "[SparseLR] lr=0.01 l1=1e-05 l2=0.0001\n",
      "[SparseLR] Building model\n",
      "[SparseLR] Training model\n",
      "[SparseLR] #examples=6714  #epochs=50  batch size=100\n",
      "[SparseLR] Epoch 0 (3.11s)\tAvg. loss=0.660310\tNNZ=122840\n",
      "[SparseLR] Epoch 25 (68.56s)\tAvg. loss=0.616328\tNNZ=122840\n",
      "[SparseLR] Epoch 49 (130.16s)\tAvg. loss=0.639674\tNNZ=122840\n",
      "[SparseLR] Training done (130.17s)\n",
      "[SparseLR] Loaded model <SparseLR_2>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.461187</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.550409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.679054</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.458234</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.537063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.529655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.454988</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.528996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.435841</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.526738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.522013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.438073</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.521858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.446602</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.519774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>0.517385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.448878</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.516499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.416842</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.513619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.475504</td>\n",
       "      <td>0.557432</td>\n",
       "      <td>0.513219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.356688</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.438070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.346535</td>\n",
       "      <td>0.591216</td>\n",
       "      <td>0.436954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.343936</td>\n",
       "      <td>0.584459</td>\n",
       "      <td>0.433041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.397476</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>0.411093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.361979</td>\n",
       "      <td>0.469595</td>\n",
       "      <td>0.408824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.346247</td>\n",
       "      <td>0.483108</td>\n",
       "      <td>0.403385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr  l1_penalty  l2_penalty     Prec.      Rec.        F1\n",
       "2   0.001000    0.000010    0.000010  0.456140  0.702703  0.553191\n",
       "3   0.001000    0.000001    0.001000  0.461187  0.682432  0.550409\n",
       "13  0.001000    0.000010    0.000100  0.455782  0.679054  0.545455\n",
       "0   0.010000    0.001000    0.000100  0.458234  0.648649  0.537063\n",
       "11  0.001000    0.000001    0.001000  0.447552  0.648649  0.529655\n",
       "14  0.000100    0.010000    0.000010  0.454988  0.631757  0.528996\n",
       "12  0.000100    0.000100    0.000010  0.435841  0.665541  0.526738\n",
       "7   0.010000    0.000010    0.010000  0.488235  0.560811  0.522013\n",
       "1   0.000100    0.000001    0.001000  0.438073  0.645270  0.521858\n",
       "8   0.000100    0.010000    0.000001  0.446602  0.621622  0.519774\n",
       "4   0.010000    0.000100    0.000010  0.439716  0.628378  0.517385\n",
       "10  0.000100    0.010000    0.000100  0.448878  0.608108  0.516499\n",
       "17  0.010000    0.000010    0.000001  0.416842  0.668919  0.513619\n",
       "19  0.010000    0.000010    0.000100  0.475504  0.557432  0.513219\n",
       "16  0.000001    0.010000    0.001000  0.356688  0.567568  0.438070\n",
       "9   0.000001    0.000010    0.001000  0.346535  0.591216  0.436954\n",
       "5   0.000001    0.001000    0.000010  0.343936  0.584459  0.433041\n",
       "18  0.000010    0.010000    0.000001  0.397476  0.425676  0.411093\n",
       "15  0.000010    0.000001    0.000100  0.361979  0.469595  0.408824\n",
       "6   0.000001    0.001000    0.010000  0.346247  0.483108  0.403385"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1701)\n",
    "SLR_searcher.fit(F_dev, L_gold_dev, n_epochs=50, rebalance=0.5, print_freq=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.XGBoost_NoiseAware import XGBoost_NoiseAware\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "import numpy as np\n",
    "xgb_model = XGBoost_NoiseAware()\n",
    "xgb_model2 = XGBoost_NoiseAware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Search: <br>\n",
    "Other Hyperparameters not listed:<br>\n",
    "'subsample'<br>\n",
    "'colsample_bytree'<br>\n",
    "'lambda_val'<br>\n",
    "'alpha_val'<br>\n",
    "See: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ for details about hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 100. Search space size = 2916.\n",
      "============================================================\n",
      "[1] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 3.00e+00, gamma = 2.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[2] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[3] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 4.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[4] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 4.00e+00, gamma = 5.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[5] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 1.00e+00, gamma = 2.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[6] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 5.00e-01, num_rounds = 2.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[7] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 4.00e-01, num_rounds = 2.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[8] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 2.00e+00, gamma = 1.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[9] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 5.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[10] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 1.00e+00, gamma = 1.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[11] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 3.00e+00, gamma = 1.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[12] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 5.00e+00, gamma = 3.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[13] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 2.00e+00, gamma = 0.00e+00, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[14] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 1.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[15] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 5.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[16] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 3.00e+00, gamma = 2.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[17] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 3.00e+00, gamma = 2.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[18] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 0.00e+00, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[19] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 4.00e+00, gamma = 1.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[20] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 4.00e+00, gamma = 0.00e+00, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[21] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 3.00e+00, gamma = 1.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[22] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 2.00e+00, gamma = 3.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[23] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 2.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[24] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 1.00e+00, gamma = 0.00e+00, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[25] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 0.00e+00, num_rounds = 2.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[26] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 1.00e+00, gamma = 3.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[27] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 4.00e+00, gamma = 0.00e+00, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[28] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 3.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[29] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 5.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[30] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 2.00e+00, gamma = 5.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[31] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 2.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[32] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 2.00e+00, gamma = 5.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[33] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[34] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 3.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[35] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 2.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[36] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 4.00e+00, gamma = 2.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[37] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 3.00e+00, gamma = 5.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[38] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 2.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[39] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 3.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[40] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 1.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[41] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 4.00e+00, gamma = 3.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[42] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[43] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 4.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[44] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 2.00e+00, gamma = 4.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[45] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 1.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[46] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 6.00e+00, gamma = 3.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[47] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 5.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[48] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 1.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[49] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 1.00e-01, num_rounds = 2.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[50] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[51] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 3.00e+00, gamma = 1.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[52] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 2.00e+00, gamma = 1.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[53] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 1.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[54] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 0.00e+00, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[55] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 4.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[56] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 3.00e+00, gamma = 2.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[57] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 3.00e+00, gamma = 0.00e+00, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[58] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 1.00e+00, gamma = 3.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[59] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 0.00e+00, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[60] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 3.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[61] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[62] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 2.00e+00, gamma = 5.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[63] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 3.00e+00, gamma = 2.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[64] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[65] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 6.00e+00, gamma = 1.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[66] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 1.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[67] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 4.00e-01, num_rounds = 2.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[68] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 1.00e+00, gamma = 2.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[69] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 3.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[70] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 3.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[71] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 4.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[72] Testing eta = 3.00e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 2.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[73] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 5.00e+00, gamma = 3.00e-01, num_rounds = 2.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[74] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 5.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[75] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 3.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[76] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 0.00e+00, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[77] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 1.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[78] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 1.00e+00, gamma = 0.00e+00, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[79] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 3.00e+00, gamma = 3.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[80] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 5.00e+00, gamma = 2.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[81] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 2.00e+00, gamma = 3.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[82] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 3.00e+00, gamma = 3.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[83] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 1.00e-01, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[84] Testing eta = 3.00e-01, max_depth = 5.00e+00, min_child_weight = 3.00e+00, gamma = 1.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[85] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 4.00e+00, gamma = 2.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[86] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 4.00e+00, gamma = 4.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[87] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 6.00e+00, gamma = 5.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[88] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 5.00e+00, gamma = 2.00e-01, num_rounds = 2.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[89] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 0.00e+00, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[90] Testing eta = 2.50e-01, max_depth = 6.00e+00, min_child_weight = 2.00e+00, gamma = 2.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[91] Testing eta = 2.00e-01, max_depth = 5.00e+00, min_child_weight = 6.00e+00, gamma = 2.00e-01, num_rounds = 2.20e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[92] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 5.00e+00, gamma = 1.00e-01, num_rounds = 3.00e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[93] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 5.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[94] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 3.00e+00, gamma = 4.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[95] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 2.00e+00, gamma = 3.00e-01, num_rounds = 2.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[96] Testing eta = 2.00e-01, max_depth = 6.00e+00, min_child_weight = 3.00e+00, gamma = 5.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[97] Testing eta = 3.00e-01, max_depth = 6.00e+00, min_child_weight = 5.00e+00, gamma = 3.00e-01, num_rounds = 1.80e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[98] Testing eta = 2.00e-01, max_depth = 4.00e+00, min_child_weight = 6.00e+00, gamma = 1.00e-01, num_rounds = 1.60e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[99] Testing eta = 2.50e-01, max_depth = 4.00e+00, min_child_weight = 3.00e+00, gamma = 0.00e+00, num_rounds = 1.40e+02\n",
      "============================================================\n",
      "============================================================\n",
      "[100] Testing eta = 2.50e-01, max_depth = 5.00e+00, min_child_weight = 2.00e+00, gamma = 3.00e-01, num_rounds = 2.80e+02\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>gamma</th>\n",
       "      <th>num_rounds</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>280</td>\n",
       "      <td>0.472813</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.556328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>180</td>\n",
       "      <td>0.470449</td>\n",
       "      <td>0.672297</td>\n",
       "      <td>0.553547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "      <td>0.474328</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.550355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>280</td>\n",
       "      <td>0.472155</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.550071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>240</td>\n",
       "      <td>0.467933</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.549512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.549020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>160</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.547718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.547425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>220</td>\n",
       "      <td>0.464623</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.547222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>280</td>\n",
       "      <td>0.464623</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.547222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.467626</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.546985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>240</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>140</td>\n",
       "      <td>0.461358</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.544952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>220</td>\n",
       "      <td>0.462264</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0.462264</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>260</td>\n",
       "      <td>0.462264</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>240</td>\n",
       "      <td>0.467312</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.544429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.467312</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.544429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.465228</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.544180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>0.458140</td>\n",
       "      <td>0.665541</td>\n",
       "      <td>0.542700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.542614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.460993</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.542420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>220</td>\n",
       "      <td>0.463942</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.542135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>180</td>\n",
       "      <td>0.463942</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.542135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>180</td>\n",
       "      <td>0.461905</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.459906</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.462830</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.541374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.540915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>280</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.540915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.540915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>180</td>\n",
       "      <td>0.453682</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.532775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>280</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.532578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.531680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0.447796</td>\n",
       "      <td>0.652027</td>\n",
       "      <td>0.530949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>240</td>\n",
       "      <td>0.454327</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.530899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>260</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.530726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.450472</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.530556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.450472</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.530556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>220</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.530387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>160</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.530387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>160</td>\n",
       "      <td>0.449412</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.529820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "      <td>0.454106</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.529577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>240</td>\n",
       "      <td>0.452153</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>140</td>\n",
       "      <td>0.452153</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>240</td>\n",
       "      <td>0.450237</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.529248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280</td>\n",
       "      <td>0.450237</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.529248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>140</td>\n",
       "      <td>0.448357</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.529086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>260</td>\n",
       "      <td>0.447307</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.528354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>160</td>\n",
       "      <td>0.445476</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.528198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0.452785</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.527504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.526611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>140</td>\n",
       "      <td>0.447867</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.526462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>160</td>\n",
       "      <td>0.448687</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.525874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>280</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.524862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>180</td>\n",
       "      <td>0.448441</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.524544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>140</td>\n",
       "      <td>0.445498</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.523677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0.445498</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.523677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>260</td>\n",
       "      <td>0.444181</td>\n",
       "      <td>0.631757</td>\n",
       "      <td>0.521618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0.442353</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.521498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eta  max_depth  min_child_weight  gamma  num_rounds     Prec.      Rec.  \\\n",
       "0   0.30          6                 3    0.2         280  0.472813  0.675676   \n",
       "7   0.20          6                 2    0.1         180  0.470449  0.672297   \n",
       "17  0.30          5                 6    0.0         240  0.474328  0.655405   \n",
       "76  0.25          6                 5    0.1         280  0.472155  0.658784   \n",
       "11  0.30          4                 5    0.3         240  0.467933  0.665541   \n",
       "62  0.30          5                 3    0.2         300  0.468900  0.662162   \n",
       "97  0.20          4                 6    0.1         160  0.463700  0.668919   \n",
       "12  0.30          6                 2    0.0         140  0.457014  0.682432   \n",
       "59  0.30          6                 4    0.3         220  0.464623  0.665541   \n",
       "68  0.30          4                 2    0.3         280  0.464623  0.665541   \n",
       "96  0.30          6                 5    0.3         180  0.467626  0.658784   \n",
       "87  0.20          4                 5    0.2         240  0.460465  0.668919   \n",
       "33  0.25          6                 5    0.3         140  0.461358  0.665541   \n",
       "90  0.20          5                 6    0.2         220  0.462264  0.662162   \n",
       "13  0.20          5                 5    0.1         140  0.462264  0.662162   \n",
       "10  0.20          6                 3    0.1         260  0.462264  0.662162   \n",
       "16  0.30          5                 3    0.2         240  0.467312  0.652027   \n",
       "91  0.25          4                 5    0.1         300  0.467312  0.652027   \n",
       "56  0.25          6                 3    0.0         260  0.465228  0.655405   \n",
       "57  0.25          6                 1    0.3         300  0.458140  0.665541   \n",
       "26  0.30          5                 4    0.0         260  0.468137  0.645270   \n",
       "48  0.25          4                 2    0.1         200  0.460993  0.658784   \n",
       "47  0.25          6                 4    0.1         220  0.463942  0.652027   \n",
       "42  0.20          5                 5    0.4         180  0.463942  0.652027   \n",
       "52  0.25          5                 6    0.1         180  0.461905  0.655405   \n",
       "80  0.30          5                 2    0.3         180  0.459906  0.658784   \n",
       "64  0.20          6                 6    0.1         300  0.462830  0.652027   \n",
       "71  0.30          4                 2    0.2         300  0.458824  0.658784   \n",
       "99  0.25          5                 2    0.3         280  0.458824  0.658784   \n",
       "21  0.25          5                 2    0.3         300  0.458824  0.658784   \n",
       "..   ...        ...               ...    ...         ...       ...       ...   \n",
       "22  0.20          6                 4    0.2         180  0.453682  0.645270   \n",
       "45  0.30          6                 6    0.3         280  0.458537  0.635135   \n",
       "24  0.20          5                 1    0.0         200  0.448837  0.652027   \n",
       "82  0.30          5                 6    0.1         140  0.447796  0.652027   \n",
       "38  0.25          5                 5    0.3         240  0.454327  0.638514   \n",
       "15  0.30          4                 3    0.2         260  0.452381  0.641892   \n",
       "69  0.25          4                 2    0.3         180  0.450472  0.645270   \n",
       "6   0.20          4                 2    0.4         200  0.450472  0.645270   \n",
       "46  0.25          6                 4    0.5         220  0.448598  0.648649   \n",
       "25  0.20          6                 1    0.3         160  0.448598  0.648649   \n",
       "61  0.20          5                 2    0.5         160  0.449412  0.645270   \n",
       "19  0.20          4                 4    0.0         240  0.454106  0.635135   \n",
       "85  0.20          5                 4    0.4         240  0.452153  0.638514   \n",
       "81  0.25          6                 3    0.3         140  0.452153  0.638514   \n",
       "44  0.20          6                 5    0.1         240  0.450237  0.641892   \n",
       "58  0.25          4                 2    0.0         280  0.450237  0.641892   \n",
       "30  0.30          5                 1    0.2         140  0.448357  0.645270   \n",
       "94  0.25          4                 2    0.3         260  0.447307  0.645270   \n",
       "95  0.20          6                 3    0.5         160  0.445476  0.648649   \n",
       "98  0.25          4                 3    0.0         140  0.452785  0.631757   \n",
       "75  0.30          5                 1    0.0         240  0.444444  0.648649   \n",
       "53  0.25          4                 2    0.0         240  0.449761  0.635135   \n",
       "1   0.20          4                 4    0.4         140  0.447867  0.638514   \n",
       "84  0.25          4                 4    0.2         160  0.448687  0.635135   \n",
       "2   0.30          5                 1    0.4         280  0.443925  0.641892   \n",
       "93  0.25          4                 3    0.4         180  0.448441  0.631757   \n",
       "35  0.25          4                 4    0.2         140  0.445498  0.635135   \n",
       "77  0.20          5                 1    0.0         140  0.445498  0.635135   \n",
       "36  0.20          4                 3    0.5         260  0.444181  0.631757   \n",
       "88  0.20          5                 6    0.0         140  0.442353  0.635135   \n",
       "\n",
       "          F1  \n",
       "0   0.556328  \n",
       "7   0.553547  \n",
       "17  0.550355  \n",
       "76  0.550071  \n",
       "11  0.549512  \n",
       "62  0.549020  \n",
       "97  0.547718  \n",
       "12  0.547425  \n",
       "59  0.547222  \n",
       "68  0.547222  \n",
       "96  0.546985  \n",
       "87  0.545455  \n",
       "33  0.544952  \n",
       "90  0.544444  \n",
       "13  0.544444  \n",
       "10  0.544444  \n",
       "16  0.544429  \n",
       "91  0.544429  \n",
       "56  0.544180  \n",
       "57  0.542700  \n",
       "26  0.542614  \n",
       "48  0.542420  \n",
       "47  0.542135  \n",
       "42  0.542135  \n",
       "52  0.541899  \n",
       "80  0.541667  \n",
       "64  0.541374  \n",
       "71  0.540915  \n",
       "99  0.540915  \n",
       "21  0.540915  \n",
       "..       ...  \n",
       "22  0.532775  \n",
       "45  0.532578  \n",
       "24  0.531680  \n",
       "82  0.530949  \n",
       "38  0.530899  \n",
       "15  0.530726  \n",
       "69  0.530556  \n",
       "6   0.530556  \n",
       "46  0.530387  \n",
       "25  0.530387  \n",
       "61  0.529820  \n",
       "19  0.529577  \n",
       "85  0.529412  \n",
       "81  0.529412  \n",
       "44  0.529248  \n",
       "58  0.529248  \n",
       "30  0.529086  \n",
       "94  0.528354  \n",
       "95  0.528198  \n",
       "98  0.527504  \n",
       "75  0.527473  \n",
       "53  0.526611  \n",
       "1   0.526462  \n",
       "84  0.525874  \n",
       "2   0.524862  \n",
       "93  0.524544  \n",
       "35  0.523677  \n",
       "77  0.523677  \n",
       "36  0.521618  \n",
       "88  0.521498  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta_param = RangeParameter('eta', .2, .3, step=.05)\n",
    "max_depth_param  = RangeParameter('max_depth', 4, 6, step=1)\n",
    "min_child_weight_param  = RangeParameter('min_child_weight', 1, 6, step=1)\n",
    "gamma_param = RangeParameter('gamma', 0, .5, step = .1)\n",
    "num_rounds_param = RangeParameter('num_rounds', 140, 300, 20)\n",
    "\n",
    "xgb_searcher = RandomSearch(session, xgb_model, F_train, train_marginals, [eta_param, max_depth_param, min_child_weight_param, gamma_param, num_rounds_param], n=100)\n",
    "\n",
    "np.random.seed(1701)\n",
    "xgb_searcher.fit(F_dev, L_gold_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or run without the hyperparameter search:\n",
    "```\n",
    "    xgb_model.train(F_train, train_marginals, num_rounds=250)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   50,\n",
    "    'dropout':    0.5,\n",
    "    'rebalance':  0.25,\n",
    "    'print_freq': 5\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "dev_labels = (np.ravel(L_gold_dev.todense()) + 1) / 2\n",
    "lstm.train(train, train_marginals, dev_candidates=dev, dev_labels=dev_labels, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Scoring on the test set\n",
    "\n",
    "Finally, we'll evaluate our performance on the blind test set of 500 documents. We'll load labels similar to how we did for the development set, and use the `score` function of our extraction model to see how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.704\n",
      "Neg. class accuracy: 0.588\n",
      "Precision            0.452\n",
      "Recall               0.704\n",
      "F1                   0.551\n",
      "----------------------------------------\n",
      "TP: 1060 | FP: 1283 | TN: 1832 | FN: 445\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = SLR_model.score(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.71\n",
      "Neg. class accuracy: 0.601\n",
      "Precision            0.462\n",
      "Recall               0.71\n",
      "F1                   0.56\n",
      "----------------------------------------\n",
      "TP: 1068 | FP: 1244 | TN: 1871 | FN: 437\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _ = xgb_model.score(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, _, _, _ = lstm.score(session, F_test, L_gold_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
